{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rough implemention of attention model to understand what's going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_inputs = [np.random.randint(2,101,n) for n in  np.random.randint(5,20,2500)]\n",
    "target_inputs = [np.random.randint(2,101,n) for n in  np.random.randint(5,20,2500)]\n",
    "\n",
    "# print(source_inputs)\n",
    "# print(target_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_lens = list(map(len,source_inputs))\n",
    "target_lens = list(map(len,target_inputs))\n",
    "\n",
    "# print(input_lens, output_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "padded_inputs = np.array([np.concatenate((i,\n",
    "            [0 for j in range(20-len(i))])) for i in source_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_mask_array = 1.0*(padded_inputs > 0.)\n",
    "#source_mask_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "padded_outputs = np.array([np.concatenate((i,\n",
    "            [0 for j in range(20-len(i))])) for i in target_inputs])\n",
    "#padded_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_mask_array = 1.0*(padded_outputs>0)\n",
    "#target_mask_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "source_vocab_size = 100\n",
    "target_vocab_size = 100\n",
    "embed_size = 200\n",
    "hidden_size = 250\n",
    "align_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_ids = tf.placeholder(dtype=tf.int32,shape=[None,None])\n",
    "source_seq_lens = tf.placeholder(dtype=tf.int32,shape=[None])\n",
    "source_mask = tf.placeholder(dtype=tf.float32,shape=[None,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_embeddings = tf.get_variable('source_embedding_matrix',\n",
    "                            [source_vocab_size+1, embed_size])\n",
    "enc_inputs = tf.nn.embedding_lookup(source_embeddings, source_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc_fw_cell = tf.contrib.rnn.GRUCell(hidden_size)\n",
    "enc_bw_cell = tf.contrib.rnn.GRUCell(hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc_outputs, states = \\\n",
    "tf.nn.bidirectional_dynamic_rnn(cell_fw = enc_fw_cell, \n",
    "                                         cell_bw = enc_bw_cell,\n",
    "                                         inputs = enc_inputs,\n",
    "                                         sequence_length = source_seq_lens,\n",
    "                                         dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concat_enc_outputs = tf.concat(enc_outputs, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 500)\n"
     ]
    }
   ],
   "source": [
    "print(concat_enc_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bw_enc_output1 = enc_outputs[-1][:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U = tf.get_variable('U',[hidden_size,hidden_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_state = tf.matmul(bw_enc_output1,U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = tf.placeholder(tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = tf.get_variable('W',[1,2*hidden_size,align_size],dtype=tf.float32)\n",
    "W_rep = tf.tile(W,[batch_size,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.matmul(concat_enc_outputs,W_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 150)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V = tf.get_variable('V',[hidden_size,align_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = tf.get_variable('v',[1,align_size,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_rep = tf.tile(v,[batch_size,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 150, 1)\n"
     ]
    }
   ],
   "source": [
    "print(v_rep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P = tf.get_variable('P',[hidden_size,target_vocab_size+2])\n",
    "b = tf.get_variable('b',[target_vocab_size+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_embeddings = tf.get_variable('target_embedding_matrix',\n",
    "                            [target_vocab_size+2, embed_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('RNN'):\n",
    "    decoder_cell = tf.contrib.rnn.GRUCell(hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder_embed = tf.nn.embedding_lookup(target_embeddings, \n",
    "                                       tf.ones([batch_size],tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_output = tf.placeholder(tf.int32,[None,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_mask = tf.placeholder(dtype=tf.float32,shape=[None,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_seq_lens = tf.placeholder(dtype=tf.int32,shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits = []\n",
    "for t in range(decoder_length):\n",
    "    with tf.variable_scope('RNN'):\n",
    "        if t > 0:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        r_t = tf.matmul(decoder_state,V)\n",
    "        \n",
    "        tanh_input = X + tf.expand_dims(r_t,axis=1)\n",
    "        u_t = tf.matmul(tanh_input,v_rep)\n",
    "        u_t = tf.squeeze(u_t,axis=2)\n",
    "\n",
    "        exp_u_t = tf.exp(u_t)\n",
    "        softmax_denom = tf.reduce_sum(exp_u_t*source_mask,axis=1,keep_dims=True)\n",
    "        a_t = exp_u_t/softmax_denom\n",
    "        a_t = a_t*source_mask\n",
    "\n",
    "        a_expn = tf.expand_dims(a_t,axis=1)\n",
    "        c_t = tf.matmul(a_expn,concat_enc_outputs)\n",
    "        c_t = tf.squeeze(c_t,axis=1)\n",
    "\n",
    "        decoder_input = tf.concat([decoder_embed,c_t],\n",
    "                                  axis=1)\n",
    "        decoder_state,_ = decoder_cell(decoder_input,\n",
    "                                       decoder_state) \n",
    "\n",
    "        logit = tf.nn.xw_plus_b(decoder_state,P,b)\n",
    "        logits.append(tf.argmax(logit, 1))\n",
    "        onehot = tf.one_hot(decoder_output[:,t],\n",
    "                            depth=target_vocab_size+2)\n",
    "        \n",
    "        \n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                        logits = logit,\n",
    "                        labels = onehot\n",
    "                    )\n",
    "        \n",
    "        xe_mask = tf.cast(tf.greater(decoder_output[:,t],0),tf.float32)\n",
    "        \n",
    "        cross_entropy = xe_mask*cross_entropy\n",
    "        \n",
    "        loss = tf.reduce_sum(cross_entropy)\n",
    "        \n",
    "        \n",
    "\n",
    "        total_loss += loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits_mat = tf.stack(logits,axis=0)\n",
    "    \n",
    "avg_loss = total_loss / tf.reduce_sum(target_mask)\n",
    "train_op = tf.train.AdamOptimizer(1e-4).minimize(avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(20), Dimension(None)])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_examples = len(padded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size_ = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Epoch 0==\n",
      "[[78 78 95 95 95 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30]\n",
      " [ 9  9 95 95 95 95 95 95 95 95 95 30 30 30 30 30 30 30 30 30]\n",
      " [95 95 95 95 95 95 30 30 30 30 30 30 30 30 30 30 30 30 30 30]\n",
      " [46 46 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95]\n",
      " [35 20 44 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95]]\n",
      "[[28 23  7 74 95 34  8 12 92 93 67 60 31 91  0  0  0  0  0  0]\n",
      " [11 14 61 28 43 20 59 36 80 64 90  3 14 26  0  0  0  0  0  0]\n",
      " [89 85 17  2 63 53 84 65 42 22 81 10  0  0  0  0  0  0  0  0]\n",
      " [24 52 57 15  5 67 47 40 76 64 37 95 29 91 24  0  0  0  0  0]\n",
      " [37 80 77 12  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "==Average Loss=4.61335==\n",
      "==Epoch 1==\n",
      "==Average Loss=4.59202==\n",
      "==Epoch 2==\n",
      "==Average Loss=4.56919==\n",
      "==Epoch 3==\n",
      "==Average Loss=4.54154==\n",
      "==Epoch 4==\n",
      "==Average Loss=4.50101==\n",
      "==Epoch 5==\n",
      "==Average Loss=4.42554==\n",
      "==Epoch 6==\n",
      "==Average Loss=4.33243==\n",
      "==Epoch 7==\n",
      "==Average Loss=4.22893==\n",
      "==Epoch 8==\n",
      "==Average Loss=4.13206==\n",
      "==Epoch 9==\n",
      "==Average Loss=4.04913==\n",
      "==Epoch 10==\n",
      "[[ 6 60 60 60 60 60 60 60 60 60 95 95 95 95 95 95 95 95 95 95]\n",
      " [58 10 10 10 10 10 10 10 10  2  2  2  2  2  2  2  2  2  2  2]\n",
      " [22 22 22 22 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68]\n",
      " [51  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 69]\n",
      " [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30]]\n",
      "[[55 30 45 33 60  6 59 80 70  6 27 77 12 95 71 24  0  0  0  0]\n",
      " [73  8  2 53 93 58 21 10 75 57  0  0  0  0  0  0  0  0  0  0]\n",
      " [65 76 69 17  9 86 48  3 75 35 15 12  2 23 50 68 54 18  0  0]\n",
      " [ 9 38  6 10 48 51 92  3 52 80 75  0  0  0  0  0  0  0  0  0]\n",
      " [54 63 91 75 65  5 98 30  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "==Average Loss=3.96947==\n",
      "==Epoch 11==\n",
      "==Average Loss=3.89173==\n",
      "==Epoch 12==\n",
      "==Average Loss=3.81864==\n",
      "==Epoch 13==\n",
      "==Average Loss=3.74881==\n",
      "==Epoch 14==\n",
      "==Average Loss=3.68174==\n",
      "==Epoch 15==\n",
      "==Average Loss=3.61753==\n",
      "==Epoch 16==\n",
      "==Average Loss=3.55704==\n",
      "==Epoch 17==\n",
      "==Average Loss=3.50046==\n",
      "==Epoch 18==\n",
      "==Average Loss=3.44814==\n",
      "==Epoch 19==\n",
      "==Average Loss=3.39916==\n",
      "==Epoch 20==\n",
      "[[79 79 79 19 19 19 19 19 19 19 29 29 29 29 29 29 19 19 19 19]\n",
      " [85 84 84 84 84 84 84 84 22 22 22 22 22 22 22 22 22 22 22 22]\n",
      " [18 56 56 56 56 56 56 56 56 56 29 29 29 29 29 29 29 29 29 29]\n",
      " [19 19 19 19  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3]\n",
      " [25 25 25 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88]]\n",
      "[[71 64 79 91 43 28 78 29 19 72  2 41 94  0  0  0  0  0  0  0]\n",
      " [89 85 17  2 63 53 84 65 42 22 81 10  0  0  0  0  0  0  0  0]\n",
      " [ 7  2 18 56 29  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [31 19 22 31 38 53  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [86 78 30 25 16 88  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "==Average Loss=3.35265==\n",
      "==Epoch 21==\n",
      "==Average Loss=3.30792==\n",
      "==Epoch 22==\n",
      "==Average Loss=3.26460==\n",
      "==Epoch 23==\n",
      "==Average Loss=3.22287==\n",
      "==Epoch 24==\n",
      "==Average Loss=3.18298==\n",
      "==Epoch 25==\n",
      "==Average Loss=3.14520==\n",
      "==Epoch 26==\n",
      "==Average Loss=3.10976==\n",
      "==Epoch 27==\n",
      "==Average Loss=3.07603==\n",
      "==Epoch 28==\n",
      "==Average Loss=3.04266==\n",
      "==Epoch 29==\n",
      "==Average Loss=3.00920==\n",
      "==Epoch 30==\n",
      "[[43 43 43 43 43 84 84 84 43 43 43 43 43 43 43 43 43 43 43 43]\n",
      " [73 73 73 73 80 80 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\n",
      " [81 82 82 82 82 82 83 83 83 83 83 83 83 83 83 83 83 83 83 83]\n",
      " [63 63 63 66 14 14 14 95 95 15 15 15 15  9  9  9 15 15 15 15]\n",
      " [35 35 32 32 32 16 16 16 26 26 75 75 75 75 75 75 75 75 75 75]]\n",
      "[[ 62  43  51  38  68  84  55  77  51  16  32  24  10  70  90  43  84   0\n",
      "    0   0]\n",
      " [ 26  73  52  16  80  61  62  13  45  39  65 100  85  10  10   0   0   0\n",
      "    0   0]\n",
      " [ 74  31  33  87  92  82  69  56  20  67  32  83  33  10  89  60   0   0\n",
      "    0   0]\n",
      " [ 97  63  58  62   9  44  14  92  95  15   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 84  35  52  32  94  95  26  93 100  75  99  30  26   0   0   0   0   0\n",
      "    0   0]]\n",
      "==Average Loss=2.97736==\n",
      "==Epoch 31==\n",
      "==Average Loss=2.94784==\n",
      "==Epoch 32==\n",
      "==Average Loss=2.91985==\n",
      "==Epoch 33==\n",
      "==Average Loss=2.89313==\n",
      "==Epoch 34==\n",
      "==Average Loss=2.86650==\n",
      "==Epoch 35==\n",
      "==Average Loss=2.83709==\n",
      "==Epoch 36==\n",
      "==Average Loss=2.80935==\n",
      "==Epoch 37==\n",
      "==Average Loss=2.78562==\n",
      "==Epoch 38==\n",
      "==Average Loss=2.76171==\n",
      "==Epoch 39==\n",
      "==Average Loss=2.73727==\n",
      "==Epoch 40==\n",
      "[[78 78 24 24 63 86 86 76 22 22 22 22 22 95 95 95 95 95 22 22]\n",
      " [24 24 73 57 57 57 10 44 44 44 95 95 95 95 95 95 95 95 95 95]\n",
      " [38 38 48 48 10 10 52  3  3  3  3 52 52 52 52 52 52 80 80 80]\n",
      " [43 43 43 43 38 84 84 62 77 43 43 43 43 43 43 43 43 43 43 43]\n",
      " [95 60 60 60 60 32 32 32 32 32 32 32 25 25 25 32 32 32 32 32]]\n",
      "[[49 36 55  8 35 63 30 24 76 22 95 39  0  0  0  0  0  0  0  0]\n",
      " [51 24 73 22 57 21 10 44 36 95 35  0  0  0  0  0  0  0  0  0]\n",
      " [ 9 38  6 10 48 51 92  3 52 80 75  0  0  0  0  0  0  0  0  0]\n",
      " [62 43 51 38 68 84 55 77 51 16 32 24 10 70 90 43 84  0  0  0]\n",
      " [72 95 40 68 60 25 32  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "==Average Loss=2.71308==\n",
      "==Epoch 41==\n",
      "==Average Loss=2.68947==\n",
      "==Epoch 42==\n",
      "==Average Loss=2.66654==\n",
      "==Epoch 43==\n",
      "==Average Loss=2.64431==\n",
      "==Epoch 44==\n",
      "==Average Loss=2.62272==\n",
      "==Epoch 45==\n",
      "==Average Loss=2.60174==\n",
      "==Epoch 46==\n",
      "==Average Loss=2.58138==\n",
      "==Epoch 47==\n",
      "==Average Loss=2.56172==\n",
      "==Epoch 48==\n",
      "==Average Loss=2.54304==\n",
      "==Epoch 49==\n",
      "==Average Loss=2.52580==\n",
      "==Epoch 50==\n",
      "[[ 35  35  32  32  32  16 100  40  40  75  75  75  30  30  30  75  75  75\n",
      "   75  75]\n",
      " [ 39  60  95  95  95  52  93  93  93  36  36  36  36  36  36  36  36  36\n",
      "   36  36]\n",
      " [ 78  78  78  12  12  30  30  30  99  99  99  99  99  99  99  99  51  51\n",
      "   51  51]\n",
      " [  4   4   4   4   4   4  38  38  11  11  11  11  11  11  11  11  11  11\n",
      "   11  11]\n",
      " [ 78  78  55  55  63  63  76  76  22  22  22  22  95  95  95  95  95  95\n",
      "   95  22]]\n",
      "[[ 84  35  52  32  94  95  26  93 100  75  99  30  26   0   0   0   0   0\n",
      "    0   0]\n",
      " [  6  39  37  95  15  52  93  12  36   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 20  78  25  12  78  76   4  30  51  99  21   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 68   8  13  83   4  38  11   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 49  36  55   8  35  63  30  24  76  22  95  39   0   0   0   0   0   0\n",
      "    0   0]]\n",
      "==Average Loss=2.51069==\n",
      "==Epoch 51==\n",
      "==Average Loss=2.49740==\n",
      "==Epoch 52==\n",
      "==Average Loss=2.48115==\n",
      "==Epoch 53==\n",
      "==Average Loss=2.46117==\n",
      "==Epoch 54==\n",
      "==Average Loss=2.44901==\n",
      "==Epoch 55==\n",
      "==Average Loss=2.42671==\n",
      "==Epoch 56==\n",
      "==Average Loss=2.40722==\n",
      "==Epoch 57==\n",
      "==Average Loss=2.39069==\n",
      "==Epoch 58==\n",
      "==Average Loss=2.37807==\n",
      "==Epoch 59==\n",
      "==Average Loss=2.36676==\n",
      "==Epoch 60==\n",
      "[[  3   3   3  25  25  64  64   6   6   6   6   6   6   6  81  81  36  36\n",
      "   36  36]\n",
      " [ 66  92  92   4  70  70  70  71 100  93  93  93  93  70  70  70  70  70\n",
      "   70  93]\n",
      " [ 51  13  13  70  70  70  70  70  70  70  70  70  70  70  70  70  70  70\n",
      "   70  70]\n",
      " [ 61  75  75   2   2   2   2  71  71  71  71  71   2   2   2   2   2   2\n",
      "    2   2]\n",
      " [ 73  73  73  16  80  80  13  13  13  39  39  39  39  10  10  10  10  39\n",
      "   39  39]]\n",
      "[[ 89   3  16  62  88  64  25   3  96   6   2   6  81  26  36   0   0   0\n",
      "    0   0]\n",
      " [  7  95  92   4  54  70   2  71  38  93  80 100  44   0   0   0   0   0\n",
      "    0   0]\n",
      " [  6  51  13  17  70   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 82  61  75  71   2   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 26  73  52  16  80  61  62  13  45  39  65 100  85  10  10   0   0   0\n",
      "    0   0]]\n",
      "==Average Loss=2.34976==\n",
      "==Epoch 61==\n",
      "==Average Loss=2.32957==\n",
      "==Epoch 62==\n",
      "==Average Loss=2.31371==\n",
      "==Epoch 63==\n",
      "==Average Loss=2.30007==\n",
      "==Epoch 64==\n",
      "==Average Loss=2.28423==\n",
      "==Epoch 65==\n",
      "==Average Loss=2.26744==\n",
      "==Epoch 66==\n",
      "==Average Loss=2.25255==\n",
      "==Epoch 67==\n",
      "==Average Loss=2.23944==\n",
      "==Epoch 68==\n",
      "==Average Loss=2.22500==\n",
      "==Epoch 69==\n",
      "==Average Loss=2.20817==\n",
      "==Epoch 70==\n",
      "[[87 87 91 52 52 15 51 51 81 64 83 83 83 83 83 83 83 83 64 64]\n",
      " [54 54 34 92 38 38 62 62 62 12 12 12 10 10 49 49 49 49 12 10]\n",
      " [20 12 12 10 10 13 13 13  2 41 41 17 17 97 97 97  8  8  8 73]\n",
      " [96 96 85 85 14 14  2  2  2  2  2 59 59  2  2  2  2  2  2  2]\n",
      " [30 30 23 72 38 38 38 30 30 98 23 23 23 30 30 30 98 98 98 98]]\n",
      "[[ 28  87  91  52  15  36  24  51  14  64  81  49  83   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 46  54  34  92  38 100  62  62  44  48  27  12  36  49  39  10  91  37\n",
      "    0   0]\n",
      " [ 18  20  12  10  14  13  62  34  44  70  41  17  25  97  21  52   8   0\n",
      "    0   0]\n",
      " [ 13  96  34  85  46  14   2   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 62  23  30  72   2  80  38  71  30   4  23  98  69   0   0   0   0   0\n",
      "    0   0]]\n",
      "==Average Loss=2.19520==\n",
      "==Epoch 71==\n",
      "==Average Loss=2.18699==\n",
      "==Epoch 72==\n",
      "==Average Loss=2.17549==\n",
      "==Epoch 73==\n",
      "==Average Loss=2.16092==\n",
      "==Epoch 74==\n",
      "==Average Loss=2.14768==\n",
      "==Epoch 75==\n",
      "==Average Loss=2.13590==\n",
      "==Epoch 76==\n",
      "==Average Loss=2.12342==\n",
      "==Epoch 77==\n",
      "==Average Loss=2.10943==\n",
      "==Epoch 78==\n",
      "==Average Loss=2.09635==\n",
      "==Epoch 79==\n",
      "==Average Loss=2.08346==\n",
      "==Epoch 80==\n",
      "[[66 66 66 66 33 69 69 69 68 68 68 68 68 68 68 68 68 68 68 68]\n",
      " [17 17 57 15 15 47 47 47 37 37 37 24 24 24 24 47 47 47 47 47]\n",
      " [84 84 26 29 29  4 15 15 33 33 26 26 26 26 64 64 64 64 64 64]\n",
      " [70 70 70 96 96 84 84 90 90 39 39 39 39 47 47 90 90 90 49 49]\n",
      " [48 48 94 79 57 57 57 83 83 84 84 84 52 52 52 83 83 83 28 28]]\n",
      "[[72 31 66 15 33 69 22 63 36 68 69 54 79 40 68  0  0  0  0  0]\n",
      " [24 52 57 15  5 67 47 40 76 64 37 95 29 91 24  0  0  0  0  0]\n",
      " [ 8 84 26 92 29  4 15 64 33 92 26 25 59 77  7 64 27 55  0  0]\n",
      " [60 70 18 57 96 84 69 90 81 54 39 10 47 95 40 28 75 91 31  0]\n",
      " [69 48 94 79 76 57 91 58 83 84 28 52  0  0  0  0  0  0  0  0]]\n",
      "==Average Loss=2.06567==\n",
      "==Epoch 81==\n",
      "==Average Loss=2.05308==\n",
      "==Epoch 82==\n",
      "==Average Loss=2.04537==\n",
      "==Epoch 83==\n",
      "==Average Loss=2.03902==\n",
      "==Epoch 84==\n",
      "==Average Loss=2.03142==\n",
      "==Epoch 85==\n",
      "==Average Loss=2.01171==\n",
      "==Epoch 86==\n",
      "==Average Loss=1.99619==\n",
      "==Epoch 87==\n",
      "==Average Loss=1.98734==\n",
      "==Epoch 88==\n",
      "==Average Loss=1.98160==\n",
      "==Epoch 89==\n",
      "==Average Loss=1.97603==\n",
      "==Epoch 90==\n",
      "[[49 49 49 55 43 43 54 87 87 27  9  9  9 10 10 10 10 10 10 10]\n",
      " [59 11 45 69 69 69 69 69 69 69 69 69 69 69 69 69 69 69 69 69]\n",
      " [61 61 82 64 64 39 51 32 32 32 32 32 32 12 20 20 20 32 32 32]\n",
      " [86 33 33 88 88 87 87 65 65  5 69 33 33 33 33 33 47  8  8  8]\n",
      " [93 93 59 31 31 71 71 55 55 55 92 92  4  4 11 11 11  4 24 24]]\n",
      "[[18 49 77 55 63 43 87 54 61 93 69 27  9 80 44 10 16 68 23  0]\n",
      " [39 59 11 45 69  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [58 61 82 31 64  6 78 51 40 28 32 32 18 12 65 20 93  0  0  0]\n",
      " [29 86 33 88 95 61 87 65 47  5 69 27  8  3 33 74  0  0  0  0]\n",
      " [ 7 93 59 30 31 54 61 55 71 36 18 92 72 14 24 40 34 11  4  0]]\n",
      "==Average Loss=1.96794==\n",
      "==Epoch 91==\n",
      "==Average Loss=1.95732==\n",
      "==Epoch 92==\n",
      "==Average Loss=1.94891==\n",
      "==Epoch 93==\n",
      "==Average Loss=1.94512==\n",
      "==Epoch 94==\n",
      "==Average Loss=1.97398==\n",
      "==Epoch 95==\n",
      "==Average Loss=1.95248==\n",
      "==Epoch 96==\n",
      "==Average Loss=1.95378==\n",
      "==Epoch 97==\n",
      "==Average Loss=1.91926==\n",
      "==Epoch 98==\n",
      "==Average Loss=1.90710==\n",
      "==Epoch 99==\n",
      "==Average Loss=1.89882==\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        print('==Epoch %i=='%epoch)\n",
    "        for i in range(math.ceil(num_examples/batch_size_)):\n",
    "            start = i*batch_size_\n",
    "            end = start + batch_size_\n",
    "            logits_,avg_loss_,_ = sess.run([logits_mat,avg_loss,train_op],\n",
    "                                feed_dict={\n",
    "                                           batch_size:min(num_examples, end) - start,\n",
    "                                           source_mask:source_mask_array[start:end,:],\n",
    "                                           target_mask:source_mask_array[start:end,:],\n",
    "                                           source_ids:padded_inputs[start:end], \n",
    "                                           source_seq_lens:source_lens[start:end],\n",
    "                                           target_seq_lens:source_lens[start:end],\n",
    "                                           decoder_output:padded_inputs[start:end,:],\n",
    "                                          })\n",
    "            \n",
    "        if epoch%10 == 0:\n",
    "            choices = np.random.randint(0,batch_size_,5)\n",
    "            print(logits_.T[choices])\n",
    "            print(padded_inputs[start:end,:][choices])\n",
    "        print('==Average Loss=%.5f=='%avg_loss_)\n",
    "    #     print(logits_,avg_loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49 43 44 60 18 37 34 50 46 25 55 53  0  0  0  0  0  0  0  0]\n",
      "[43 44 44 60 60 18 34 46 46 55 53 53 53 53 25 25 25 25 25 25]\n",
      "\n",
      "[84 84  5 17 12 15 28 35  9 68 51 32  0  0  0  0  0  0  0  0]\n",
      "[84 84  5 17 15 15 15 51 51 32 32 32 32 32 32 32 32 32 32 32]\n",
      "\n",
      "[74 31 33 87 92 82 69 56 20 67 32 83 33 10 89 60  0  0  0  0]\n",
      "[31 31 31 87 82 27 23 20 20 20 33 33 33 89 10 10 10 33 33 33]\n",
      "\n",
      "[24 52 57 15  5 67 47 40 76 64 37 95 29 91 24  0  0  0  0  0]\n",
      "[17 17 57 15 15 47 47 76 64 95 95 95 29 29 24 24 24 47 76 76]\n",
      "\n",
      "[71 19 77 40  3 89 31  3 86 78  0  0  0  0  0  0  0  0  0  0]\n",
      "[19 19 77 40  3  3  3  3 78 78 78 78 31 31 31  3  3  3 78 78]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "choices = np.random.randint(0,batch_size_,5)\n",
    "for choice in choices:\n",
    "    print(padded_inputs[start:end,:][choice])\n",
    "    print(logits_.T[choice])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "same = np.sum((logits_.T==padded_inputs[start:end,:]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inds = np.argsort(same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 84 26 92 29  4 15 64 33 92 26 25 59 77  7 64 27 55  0  0]\n",
      "[84 84 26 92 29 15 15 64 64 33 26 26 26 77 64 64 64 64 64 64]\n",
      "9\n",
      "\n",
      "[98 69 60 67 40 60 65 13 21 59 85 10 90 48 25  0  0  0  0  0]\n",
      "[69 69 60 60 40 60 65 59 59 59 10 10 48 48 48 48 48 48 48 48]\n",
      "8\n",
      "\n",
      "[ 26  73  52  16  80  61  62  13  45  39  65 100  85  10  10   0   0   0\n",
      "   0   0]\n",
      "[ 73  73  16  16  61  61  13  13  39  39  39 100  10  10  10  10  10  39\n",
      "  39 100]\n",
      "8\n",
      "\n",
      "[ 46  54  34  92  38 100  62  62  44  48  27  12  36  49  39  10  91  37\n",
      "   0   0]\n",
      "[54 54 34 92 38 62 62 62 12 12 12 12 12 49 49 49 49 49 49 10]\n",
      "8\n",
      "\n",
      "[58 61 82 31 64  6 78 51 40 28 32 32 18 12 65 20 93  0  0  0]\n",
      "[61 61 82 31 64 51 51 32 32 32 32 32 32 12 20 20 20 32 32 32]\n",
      "8\n",
      "\n",
      "[ 2 58 31 54 24 94 52 87 80  9 94 72 69 71 98 40  0  0  0  0]\n",
      "[58 58 31 31 54 54 52 80 80  9 94 72 71 71 71 71 40 98  9  9]\n",
      "8\n",
      "\n",
      "[29 86 33 88 95 61 87 65 47  5 69 27  8  3 33 74  0  0  0  0]\n",
      "[86 33 33 88 64 87 87 65  5  5 69 69 33 33 33 33 47  8  5  5]\n",
      "7\n",
      "\n",
      "[11 71 26 61 47 98 74  7 93 24  0  0  0  0  0  0  0  0  0  0]\n",
      "[11 71 26 61 47 98 93 93 93 93 93 93 93 93 93 93 93 93 93 24]\n",
      "7\n",
      "\n",
      "[85 70 39 69 71 76 87 99 21 12 36 24 10 28 20 36 23 48 63  0]\n",
      "[70 70 39 76 76 76 87 21 12 36 36 36 10 10 10 23 23 23 36 36]\n",
      "7\n",
      "\n",
      "[ 14  76   4  63  15  52  20  43  86  42 100  76   6   3  98  37   0   0\n",
      "   0   0]\n",
      "[ 76  76  63  15  15  52  20  20  86  86 100 100  98  98  98  98  42  42\n",
      "  42  42]\n",
      "7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "choices = inds[-10:][::-1]\n",
    "for choice in choices:\n",
    "    print(padded_inputs[start:end,:][choice])\n",
    "    print(logits_.T[choice])\n",
    "    print(same[choice])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
